# AI-EnergyForcastR4
AI-Driven Predictive Maintenance for Renewable Energy Assets 
# AI-Driven Predictive Maintenance for Renewable Energy Assets

This project develops a cross-platform application for predictive maintenance of renewable energy assets (wind turbines, solar panels, inverters, batteries). It uses IoT sensor data, external weather/solar APIs, and AI/ML models to forecast failures and optimize maintenance schedules.

---

## üöÄ Features
- Real-time sensor data ingestion (temperature, humidity, irradiance, wind speed).
- External API integration (OpenWeather, NASA POWER, Tomorrow.io).
- Local PostgreSQL + TimescaleDB storage for time-series data.
- Preprocessing scripts for normalization, cleaning, and interpolation.
- Ready for deployment on Raspberry Pi 4, but fully compatible with Mac and Windows laptops during development.

---

## üõ†Ô∏è Development Setup

### 1. Clone Repository
```bash
AI-EnergyForcastR4/
‚îÇ
‚îú‚îÄ‚îÄ db/                     # Database setup and connectors
‚îÇ   ‚îú‚îÄ‚îÄ db_connector.py     # Python script to handles DB connection
‚îÇ   ‚îú‚îÄ‚îÄ db_ingest.py        # Python script to ingestion script (imports connector)
‚îÇ   ‚îú‚îÄ‚îÄ test_connection.py  # Python script for quick connection test
‚îÇ   ‚îî‚îÄ‚îÄ schema.sql          # SQL table definitions
‚îÇ
‚îú‚îÄ‚îÄ data/                 
‚îÇ   ‚îú‚îÄ‚îÄ sensor_logs.txt   # plain text log file 
‚îÇ   ‚îî‚îÄ‚îÄ sensor_data.csv   # CSV file 
‚îÇ
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ requirements.txt      # List of Python dependencies
‚îú‚îÄ‚îÄ README.md             # Documentation for setup and usage
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ ingestion.log         # today‚Äôs log)
‚îÇ   ‚îî‚îÄ‚îÄ ingestion.log.2026-01-20  #yesterday‚Äôs log, auto‚Äëcreated at midnight
‚îÇ
‚îú‚îÄ‚îÄ sensors/              # Scripts for sensor data (real or simulated)
‚îÇ   ‚îî‚îÄ‚îÄ sensor_ingest.py  # First script: generate or simulate sensor readings
‚îÇ
‚îú‚îÄ‚îÄ api_wrappers/         # External API modules
‚îÇ   ‚îî‚îÄ‚îÄ openweather.py    # First wrapper: fetch weather data
‚îÇ   ‚îî‚îÄ‚îÄ nasa_power.py     # Second wrapper: fetch solar/irradiance data
‚îÇ
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/        # Data cleaning scripts
‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py     # First script: normalize and clean sensor logs
‚îÇ
‚îî‚îÄ‚îÄ notebooks/            # Jupyter notebooks for demos
    ‚îî‚îÄ‚îÄ data_pipeline_demo.ipynb  # Step-by-step interactive demo

#### my notes
'''bash
Perfect üéâ ‚Äî that package list shows your environment is now fully set up and healthy. You‚Äôve got all the core libraries installed:
requests ‚Üí API calls and HTTP requests
pandas ‚Üí data handling and analysis
numpy ‚Üí numerical computations
psycopg2-binary ‚Üí PostgreSQL connector
scikit-learn ‚Üí classical machine learning models
torch ‚Üí PyTorch deep learning framework
matplotlib ‚Üí static plotting
plotly ‚Üí interactive charts
paho-mqtt ‚Üí IoT sensor communication
Plus all their dependencies (like scipy, joblib, threadpoolctl, etc.). This means you‚Äôre ready to start coding your actual project.
PS D:\My Documents\tools\skul\bsu2024\bsu_mot512_thesis1\GithubVisualStudioCode\AI-EnergyForcastR4> python -m pip list
Package            Version
------------------ -----------
certifi            2026.1.4
charset-normalizer 3.4.4
contourpy          1.3.3
cycler             0.12.1
filelock           3.20.3
fonttools          4.61.1
fsspec             2026.1.0
idna               3.11
Jinja2             3.1.6
joblib             1.5.3
kiwisolver         1.4.9
MarkupSafe         3.0.3
matplotlib         3.10.8
mpmath             1.3.0
narwhals           2.15.0
networkx           3.6.1
numpy              2.4.1
packaging          25.0
paho-mqtt          2.1.0
pandas             2.3.3
pillow             12.1.0
pip                25.3
plotly             6.5.2
psycopg2-binary    2.9.11
pyparsing          3.3.1
python-dateutil    2.9.0.post0
pytz               2025.2
requests           2.32.5
scikit-learn       1.8.0
scipy              1.17.0
setuptools         80.9.0
six                1.17.0
sympy              1.14.0
threadpoolctl      3.6.0
torch              2.9.1
typing_extensions  4.15.0
tzdata             2025.3
urllib3            2.6.3

[always used for activating env; "venv\Scripts\activate.bat"]
[This starts PostgreSQL in the background, listening on port 5432.
Since you don‚Äôt have admin rights, it won‚Äôt be a Windows service ‚Äî you‚Äôll need to run this manually each time.
in <cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" -l logfile start>]
[Stopping PostgreSQL. When you‚Äôre done, stop the server cleanly, This shuts down PostgreSQL safely:
in cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" stop>]
[Restarting PostgreSQL, If you want to restart:
in cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" restart>]

...notes 260119;
Phase,Item,Status
Phase 1: Environment Setup,Install PostgreSQL portable binaries,Done
Phase 1: Environment Setup,Initialize database cluster (initdb),Done
Phase 1: Environment Setup,Start PostgreSQL manually (pg_ctl),Done
Phase 1: Environment Setup,Connect with psql,Done
Phase 2: Database Schema,Create energy_db database,Done
Phase 2: Database Schema,Define sensor_data table schema,Done
Phase 2: Database Schema,Verify schema with \d sensor_data,Done
Phase 3: Python Integration,Install psycopg2 driver,Done
Phase 3: Python Integration,Create db_ingest.py script,Done
Phase 3: Python Integration,Connect Python to PostgreSQL,Done
Phase 3: Python Integration,Insert test row via Python,Done
Phase 3: Python Integration,Fetch and display rows via Python,Done
Phase 4: Log Ingestion,Adapt script to read sensor_logs.txt,Done
Phase 4: Log Ingestion,Insert multiple rows from file,Done
Phase 4: Log Ingestion,Verify ingestion with query output,Done
Phase 5: Enhancements,Handle duplicate entries (unique timestamp + ON CONFLICT),Pending
Phase 5: Enhancements,Format timestamp output (seconds only),Done
Phase 5: Enhancements,Optional: pretty table output,Pending
Phase 6: Next Steps,Automate ingestion (batch file or cron job),Pending
Phase 6: Next Steps,Extend ingestion for CSV/real sensor streams,Pending
Phase 6: Next Steps,Dashboard/visualization integration,Pending

...notes 260120;
sql password = PdM
Phase,Item,Status
Phase 1: Environment Setup,Install PostgreSQL portable binaries,Done
Phase 1: Environment Setup,Initialize database cluster (initdb),Done
Phase 1: Environment Setup,Start PostgreSQL manually (pg_ctl),Done
Phase 1: Environment Setup,Connect with psql,Done
Phase 2: Database Schema,Create energy_db database,Done
Phase 2: Database Schema,Define sensor_data table schema,Done
Phase 2: Database Schema,Verify schema with \d sensor_data,Done
Phase 3: Python Integration,Install psycopg2 driver,Done
Phase 3: Python Integration,Create db_ingest.py script,Done
Phase 3: Python Integration,Connect Python to PostgreSQL,Done
Phase 3: Python Integration,Insert test row via Python,Done
Phase 3: Python Integration,Fetch and display rows via Python,Done
Phase 4: Log Ingestion,Adapt script to read sensor_logs.txt,Done
Phase 4: Log Ingestion,Insert multiple rows from file,Done
Phase 4: Log Ingestion,Verify ingestion with query output,Done
Phase 5: Enhancements,Handle duplicate entries (unique timestamp + ON CONFLICT),Done
Phase 5: Enhancements,Format timestamp output (seconds only),Done
Phase 5: Enhancements,Pretty table output (tabulate),Done
Phase 5: Enhancements,Row count before/after ingestion,Done
Phase 5: Enhancements,Skip header line in text ingestion,Done
Phase 5: Enhancements,Modularize connection into db_connector.py,Done
Phase 5: Enhancements,Add test_connection.py script,Done
Phase 5: Enhancements,Show top/bottom rows in test script,Done
Phase 6: Next Steps,Automate ingestion (batch file or cron job),Pending
Phase 6: Next Steps,Extend ingestion for CSV/real sensor streams,Pending
Phase 6: Next Steps,Dashboard/visualization integration,Pending
Phase 6: Next Steps,Add permanent log file output (logs/ingestion.log),Done
Phase 6: Next Steps,Daily log rotation (TimedRotatingFileHandler),Done
Phase 7: Visualization & Dashboard,Plot temperature vs timestamp chart,Pending
Phase 7: Visualization & Dashboard,Add multiple charts (humidity, irradiance, wind speed),Pending
Phase 7: Visualization & Dashboard,Build simple dashboard (Streamlit or Grafana),Pending
Phase 8: Real-Time Ingestion,Simulate sensor streams (append rows every minute),Pending
Phase 8: Real-Time Ingestion,Enable continuous ingestion pipeline,Pending
Phase 9: Predictive Analytics,Calculate averages/min/max/moving averages,Pending
Phase 9: Predictive Analytics,Train ML model for forecasting (scikit-learn),Pending
Phase 10: Deployment & Scaling,Containerize with Docker,Pending
Phase 10: Deployment & Scaling,Deploy to cloud (AWS/Azure/GCP),Pending
Phase 11: Web-Sensor Data Integration,Connect to OpenWeather API for local weather data,Pending
Phase 11: Web-Sensor Data Integration,Ingest NASA POWER API for solar irradiance and climate data,Pending
Phase 11: Web-Sensor Data Integration,Integrate PVOutput API for solar PV system performance,Pending
Phase 11: Web-Sensor Data Integration,Optional: Add other APIs (NOAA, Meteostat, etc.),Pending
Phase 11: Web-Sensor Data Integration,Normalize and store web-sensor data into sensor_data table,Pending
Phase 11: Web-Sensor Data Integration,Combine local sensor + web API data for richer analytics,Pending
...Phase 6: Automate Ingestion
Step 2: Windows Batch File (simple automation)
    Open Notepad.
    Paste this:
        bat
        @echo off
        cd /d "D:\My Documents\tools\skul\bsu2024\bsu_mot512_thesis1\GithubVisualStudioCode\AI-EnergyForcastR4"
        python db\db_ingest.py
    Save as run_ingest.bat in your repo root.
    Double‚Äëclick it ‚Üí ingestion runs, logs go to logs/ingestion.log.
Step 3: Schedule with Task Scheduler
    Open Task Scheduler (Windows search).
    Create a new task ‚Üí ‚ÄúRun Ingestion Daily‚Äù.
    Set trigger ‚Üí every day at 4:00 PM.
    Set action ‚Üí run run_ingest.bat.
    Save ‚Üí ingestion now runs automatically.

...notes 260121;
Phase,Item,Status
Phase 1: Environment Setup,Install PostgreSQL portable binaries,Done
Phase 1: Environment Setup,Initialize database cluster (initdb),Done
Phase 1: Environment Setup,Start PostgreSQL manually (pg_ctl),Done
Phase 1: Environment Setup,Connect with psql,Done
Phase 2: Database Schema,Create energy_db database,Done
Phase 2: Database Schema,Define sensor_data table schema,Done
Phase 2: Database Schema,Verify schema with \d sensor_data,Done
Phase 3: Python Integration,Install psycopg2 driver,Done
Phase 3: Python Integration,Create db_ingest.py script,Done
Phase 3: Python Integration,Connect Python to PostgreSQL,Done
Phase 3: Python Integration,Insert test row via Python,Done
Phase 3: Python Integration,Fetch and display rows via Python,Done
Phase 4: Log Ingestion,Adapt script to read sensor_logs.txt,Done
Phase 4: Log Ingestion,Insert multiple rows from file,Done
Phase 4: Log Ingestion,Verify ingestion with query output,Done
Phase 5: Enhancements,Handle duplicate entries (unique timestamp + ON CONFLICT),Done
Phase 5: Enhancements,Format timestamp output (seconds only),Done
Phase 5: Enhancements,Pretty table output (tabulate),Done
Phase 5: Enhancements,Row count before/after ingestion,Done
Phase 5: Enhancements,Skip header line in text ingestion,Done
Phase 5: Enhancements,Modularize connection into db_connector.py,Done
Phase 5: Enhancements,Add test_connection.py script,Done
Phase 5: Enhancements,Show top/bottom rows in test script,Done
Phase 6: Next Steps,Automate ingestion (batch file or cron job),Done
Phase 6: Next Steps,Extend ingestion for CSV/real sensor streams,Done (simulation script ready)
Phase 6: Next Steps,Dashboard/visualization integration,Done (Streamlit dashboard running)
Phase 6: Next Steps,Add permanent log file output (logs/ingestion.log),Done
Phase 6: Next Steps,Daily log rotation (TimedRotatingFileHandler),Done
Phase 7: Visualization & Dashboard,Plot temperature vs timestamp chart,Done
Phase 7: Visualization & Dashboard,Add multiple charts (humidity, irradiance, wind speed),Done
Phase 7: Visualization & Dashboard,Build simple dashboard (Streamlit with sidebar),Done
Phase 8: Real-Time Ingestion,Simulate sensor streams (append rows every 5minute),Done
Phase 8: Real-Time Ingestion,Enable continuous ingestion pipeline,Pending
Phase 9: Predictive Analytics,Calculate averages/min/max/moving averages,Pending
Phase 9: Predictive Analytics,Train ML model for forecasting (scikit-learn),Pending
Phase 10: Deployment & Scaling,Containerize with Docker,Pending
Phase 10: Deployment & Scaling,Deploy to cloud (AWS/Azure/GCP),Pending
Phase 11: Web-Sensor Data Integration,Connect to OpenWeather API for local weather data,Pending
Phase 11: Web-Sensor Data Integration,Ingest NASA POWER API for solar irradiance and climate data,Pending
Phase 11: Web-Sensor Data Integration,Integrate PVOutput API for solar PV system performance,Pending
Phase 11: Web-Sensor Data Integration,Optional: Add other APIs (NOAA, Meteostat, etc.),Pending
Phase 11: Web-Sensor Data Integration,Normalize and store web-sensor data into sensor_data table,Pending
Phase 11: Web-Sensor Data Integration,Combine local sensor + web API data for richer analytics,Pending
...Recap
    Use View ‚Üí Terminal if `Ctrl+`` doesn‚Äôt work.
    Run dashboard ‚Üí python -m streamlit run dashboard.py.
    Stop dashboard ‚Üí Ctrl + C.
    Optional background run ‚Üí Start-Process python "-m streamlit run dashboard.py".
    Now dashboard should run reliably.
    next to add OpenWeather API ingestion so dashboard shows both local sensor data and live weather data.
...work on mac.
...AI review of files:
    File,Type,Location,Lines,Status,Purpose,Issues
    dashboard.py,Python,root,60,Needs Update,Streamlit dashboard for data visualization,Hardcoded postgres credentials
    db_connector.py,Python,db/,28,‚úÖ Working,Centralized DB connection handler,Uses .env variables (proper)
    db_ingest.py,Python,db/,144,‚úÖ Working,Ingest sensor data from TXT/CSV,Proper logging with rotation
    test_connection.py,Python,db/,15,‚úÖ Working,Verify PostgreSQL connection,Simple test script
    sensor_stream_sim.py,Python,db/,30,‚úÖ Working,Real-time sensor data simulator,5-minute interval generation
    api_ingest_openweather.py,Python,db/,?,Pending,OpenWeather API integration,Not reviewed (likely incomplete)
    sensor_ingest.py,Python,sensors/,20,‚ö†Ô∏è Incomplete,Sensor data collection,Uses old path (sensor_logs.txt)
    preprocess.py,Python,preprocessing/,?,Empty,Data cleaning/normalization,No implementation yet
    openweather.py,Python,api_wrappers/,17,‚úÖ Working,OpenWeather API wrapper,API key visible (security concern)
    nasa_power.py,Python,api_wrappers/,?,Empty,NASA POWER API wrapper,No implementation yet
    requirements.txt,Text,root,23,‚ö†Ô∏è Outdated,Python dependencies list,Missing: streamlit
    schema.sql,SQL,db/,?,Empty,Database schema definition,No implementation yet
    test_imports.py,Python,root,8,‚úÖ Working,Verify library imports,Simple check
    sensor_data.csv,CSV,data/,5,‚úÖ Complete,Sample sensor data,2 rows of data
    sensor_logs.txt,Text,data/,5,‚úÖ Complete,Sensor logs (raw),5 rows after ingestion
    .env,Config,root,7,‚úÖ Configured,Environment variables,Credentials properly set for macOS
    README.md,Markdown,root,258,‚úÖ Complete,Project documentation,Well-documented
    myNotes.txt,Text,root,378,‚úÖ Complete,Development notes,Phase tracking included
    run_ingest.bat,Batch,root,?,Incomplete,Windows automation script,Not updated for macOS
..RECAP
    ‚úÖ WORKING & READY
    Database Layer: PostgreSQL running, 3 rows ingested successfully
    Ingestion Pipeline: db_ingest.py with proper logging & ON CONFLICT handling
    Connection Pool: db_connector.py uses .env for credentials (secure)
    Sensor Simulator: sensor_stream_sim.py generates data every 5 minutes
    API Wrapper: openweather.py fetches real weather data
    ‚ö†Ô∏è INCOMPLETE/NEEDS FIXES
    dashboard.py ‚Äî Hardcoded credentials, needs .env update
    requirements.txt ‚Äî Missing streamlit, plotly, etc.
    preprocess.py ‚Äî Empty (no data cleaning logic)
    nasa_power.py ‚Äî Empty (not implemented)
    schema.sql ‚Äî Empty (schema created in psql, not via SQL file)
    run_ingest.bat ‚Äî Windows-only (need macOS equivalent)
    sensor_ingest.py ‚Äî Points to wrong file path
    üîí SECURITY CONCERNS
    OpenWeather API key visible in openweather.py (should use .env)
    dashboard.py has hardcoded credentials
    üìà NEXT PRIORITIES
    Fix dashboard.py to use .env credentials
    Update requirements.txt with all dependencies
    Implement preprocess.py for data cleaning
    Implement nasa_power.py API wrapper
    Create macOS automation script (replace .bat)
    Test Streamlit dashboard end-to-end